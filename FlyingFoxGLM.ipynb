{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74fe623-2a3b-4234-b8c8-de9dc8780132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# general\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "from importlib import reload\n",
    "\n",
    "# modeling\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap\n",
    "\n",
    "# custom\n",
    "from scripts import HyperparameterTuning as HT\n",
    "from scripts import Plots, Metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "387b5115-94a5-4545-b64d-827b14a829d0",
   "metadata": {},
   "source": [
    "# Load and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "env_path = 'data/environmental_data.csv'\n",
    "bat_path = 'data/bat-level_data.csv'\n",
    "random_state = 1337\n",
    "dataset = 'env' # 'env', 'bat'\n",
    "target = 'shortage'\n",
    "rolling_forecast = True\n",
    "\n",
    "# load configs\n",
    "env_features = []\n",
    "with open('config/env_features.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        env_features.append(line.strip())\n",
    "bat_features = []\n",
    "with open('config/bat_features.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        bat_features.append(line.strip())\n",
    "rename = {}\n",
    "with open('config/rename.tsv', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split('\\t')\n",
    "        rename[line[0]] = line[1]\n",
    "    rename['Intercept'] = 'Intercept'\n",
    "\n",
    "# book keeping\n",
    "features = env_features if dataset == 'env' else bat_features\n",
    "\n",
    "# load both datasets, sort, and merge\n",
    "df_env = pd.read_csv(env_path).sort_values(\n",
    "    by=['cal_year', 'cal_month'], ascending=[True, True])\n",
    "df_bat = pd.read_csv(bat_path).sort_values(\n",
    "    by=['cal_year', 'cal_month'], ascending=[True, True])\n",
    "df = pd.merge(df_env, df_bat, on=['cal_year', 'cal_month'], how='outer')\n",
    "\n",
    "# convert categories to binary and drop missing\n",
    "df = df.replace('shortage', 1).replace('not_shortage', 0)\n",
    "df = df.dropna(subset=[target])\n",
    "df[target] = df[target].astype(int)\n",
    "\n",
    "# include season as additional feature\n",
    "to_season = {\n",
    "    12: 1,  1: 1,  2: 1,\n",
    "     3: 2,  4: 2,  5: 2,\n",
    "     6: 3,  7: 3,  8: 3,\n",
    "     9: 4, 10: 4, 11: 4,}\n",
    "df['cal_season'] = df['cal_month'].apply(lambda x: to_season[x]).astype(float)\n",
    "\n",
    "# drop rows with >50% missing features\n",
    "df = df.dropna(thresh=0.5*len(features), subset=features)\n",
    "df_missing = df.copy()\n",
    "\n",
    "# impute missing values\n",
    "n_missing = df[features].isna().sum().sum()\n",
    "n_total = len(df) * len(features)\n",
    "imp = IterativeImputer(max_iter=100, random_state=random_state)\n",
    "df[features] = imp.fit_transform(df[features])\n",
    "\n",
    "# start integer features from 0 and convert to categorical\n",
    "for feature in ['cal_year', 'cal_month']:\n",
    "    df[feature] = df[feature].astype(int)\n",
    "for feature in ['cal_season', 'cal_month']:\n",
    "    df[feature] = (df[feature] - df[feature].min()).astype('category')\n",
    "\n",
    "# reset df index starting from 0\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# summary\n",
    "print('Missing proportion: {:.2f}% values'.format(n_missing / n_total * 100))\n",
    "print('Data shape: {} months, {} features'.format(*df[features].shape))\n",
    "print('Food shortages: {} / {} ({:.2f}%)'.format(\n",
    "    df[target].sum(), len(df), df[target].sum() / len(df) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6890bdb",
   "metadata": {},
   "source": [
    "# Split data into train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6485faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "start_year = df['cal_year'].min() + 4\n",
    "test_year = 2018\n",
    "split_size = 2\n",
    "\n",
    "# convert dataframes to numpy arrays for modeling\n",
    "X, y = df[features].values, df[target].values\n",
    "years = df['cal_year'].values\n",
    "\n",
    "# get indices of training and validation sets\n",
    "split_years = np.arange(start_year, test_year, split_size)\n",
    "if rolling_forecast:\n",
    "    train_idx = np.argwhere(years < test_year).flatten()\n",
    "else:\n",
    "    train_idx = np.argwhere((years >= test_year - 4) & (years < test_year)).flatten()\n",
    "train_idxs, val_idxs = [], []\n",
    "for i, sy in enumerate(split_years):\n",
    "    if rolling_forecast:\n",
    "        train_idxs.append(np.argwhere(years < sy).flatten())\n",
    "    else:\n",
    "        train_idxs.append(np.argwhere((years >= sy-4) & (years < sy)).flatten())\n",
    "    val_idxs.append(np.argwhere((years >= sy) * (years < sy+split_size)).flatten())\n",
    "test_idx = np.argwhere(years >= test_year).flatten()\n",
    "\n",
    "# compute train/val score weights\n",
    "weights = [len(t_idx) for t_idx in train_idxs]\n",
    "\n",
    "# plot train/val/test splits\n",
    "Plots.cv_splits(\n",
    "    years, \n",
    "    cv_splits=[train_idxs, val_idxs, test_idx], \n",
    "    dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79762712",
   "metadata": {},
   "source": [
    "# Train GLM using hyperparameter grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fae5f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress PerfectSeparationWarning from statsmodels\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \n",
    "    category=statsmodels.tools.sm_exceptions.PerfectSeparationWarning)\n",
    "\n",
    "# custom GLM classifier mimicking LightGBMClassifier\n",
    "class GLMClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        add_intercept=True,\n",
    "        max_iter=100,\n",
    "        random_state=42\n",
    "    ):\n",
    "        \n",
    "        # initialize\n",
    "        self.add_intercept = add_intercept\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        self.result_ = None\n",
    "        self.eps = np.sqrt(np.finfo(float).eps)\n",
    "\n",
    "        # copy lgb evaluation metric for hyperparameter tuning script\n",
    "        self.evals_result_ = {'valid_0': {'binary_logloss': []}}\n",
    "\n",
    "    def fit(self, X, y, eval_set=None, **kwargs):\n",
    "        \n",
    "        # optional intercept\n",
    "        X = sm.add_constant(X, prepend=True) if self.add_intercept else X\n",
    "\n",
    "        # logistic regression GLM\n",
    "        model = sm.GLM(\n",
    "            y,\n",
    "            X,\n",
    "            family=sm.families.Binomial()\n",
    "        )\n",
    "\n",
    "        # fit GLM\n",
    "        self.result_ = model.fit(maxiter=self.max_iter, **kwargs)\n",
    "\n",
    "        # validation eval (if provided)\n",
    "        if eval_set is not None:\n",
    "            X_val, y_val = eval_set\n",
    "            X_val = sm.add_constant(X_val, prepend=True) if self.add_intercept else X_val\n",
    "            val_loss = log_loss(y_val, self.predict_proba(X_val)[:, 1], labels=[0, 1])\n",
    "        else:\n",
    "            val_loss = np.nan\n",
    "        self.evals_result_['valid_0']['binary_logloss'].append(val_loss)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        # preprocess\n",
    "        X = sm.add_constant(X, prepend=True) if self.add_intercept else X\n",
    "\n",
    "        # logistic regression returns p = P(y=1)\n",
    "        p = self.result_.predict(X)\n",
    "        p = np.clip(p, self.eps, 1 - self.eps)  # numeric stability\n",
    "        return np.column_stack([1 - p, p])\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        probs = self.predict_proba(X)[:, 1]\n",
    "        return (probs >= threshold).astype(int)\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        \n",
    "        # check previously stored validation losses\n",
    "        val_losses = self.evals_result_['valid_0']['binary_logloss']\n",
    "        valid_numeric_losses = [v for v in val_losses if not np.isnan(v)]\n",
    "\n",
    "        # compute log loss on given data if no valid logs are found\n",
    "        if len(valid_numeric_losses) > 0:\n",
    "            return min(valid_numeric_losses)\n",
    "        else:\n",
    "            if self.add_intercept:\n",
    "                X = sm.add_constant(X, prepend=True)\n",
    "            p = self.predict_proba(X)[:, 1]\n",
    "            return log_loss(y, p, labels=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab69f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# tune hyperparameters\n",
    "#\n",
    "\n",
    "# ignore RuntimeWarning: overflow encountered in exp\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "model_class = GLMClassifier\n",
    "\n",
    "# hyperparameter grid\n",
    "model_hyper = {\n",
    "    'add_intercept': [True, False],\n",
    "    'max_iter': list(np.arange(100)),\n",
    "}\n",
    "model_fixed = {\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "# Training hyperparams can remain empty if you have no extra parameters\n",
    "train_hyper = {}\n",
    "train_fixed = {}\n",
    "\n",
    "model_best, train_best, model_list, score_list = HT.hyperparameter_tuning(\n",
    "    model_class=model_class,\n",
    "    model_hyper=model_hyper,\n",
    "    model_fixed=model_fixed,\n",
    "    train_hyper=train_hyper,\n",
    "    train_fixed=train_fixed,\n",
    "    x=X,\n",
    "    y=y,\n",
    "    train_indices=train_idxs,\n",
    "    val_indices=val_idxs,\n",
    "    weights=None,\n",
    "    verbose=True,\n",
    "    normalize=True,\n",
    ")\n",
    "\n",
    "print(\"Best model hyperparameters:\", model_best)\n",
    "print(\"Best training hyperparameters:\", train_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6441b9",
   "metadata": {},
   "source": [
    "# Plot model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Plots)\n",
    "reload(Metrics)\n",
    "\n",
    "def predict(train_idx, val_idx):\n",
    "\n",
    "    # center and scale\n",
    "    scaler = StandardScaler().fit(X[train_idx])\n",
    "    x_train = scaler.transform(X[train_idx])\n",
    "    x_val = scaler.transform(X[val_idx])\n",
    "\n",
    "    # fit model\n",
    "    model = model_class(\n",
    "        **model_best, \n",
    "        **model_fixed,\n",
    "    ).fit(\n",
    "        X=x_train,\n",
    "        y=y[train_idx],\n",
    "        eval_set=(x_val, y[val_idx]),\n",
    "        **train_best,\n",
    "        **train_fixed,\n",
    "    )\n",
    "\n",
    "    # predict probabilities\n",
    "    y_pred_train = model.predict_proba(x_train)[:, 1]\n",
    "    y_pred_val = model.predict_proba(x_val)[:, 1]\n",
    "\n",
    "    return y_pred_train, y_pred_val, model\n",
    "\n",
    "# compute predictions for each set\n",
    "y_prob_train = [predict(t, v)[0] for t, v in zip(train_idxs, val_idxs)]\n",
    "y_prob_train.append(predict(train_idx, test_idx)[0])\n",
    "y_prob_val = np.concatenate([predict(t, v)[1] for t, v in zip(train_idxs, val_idxs)])\n",
    "y_prob_test = predict(np.arange(test_idx[0]), test_idx)[1]\n",
    "y_prob = np.concatenate([y_prob_train[0], y_prob_val, y_prob_test])\n",
    "\n",
    "# compute thresholds for each set\n",
    "thresholds = [Metrics.get_threshold(y[v], y_prob[v]) for v in val_idxs]\n",
    "\n",
    "# create dates from years and months\n",
    "dates = df['cal_year'].astype(str) + '-' + df['cal_month'].astype(int).astype(str)\n",
    "dates = pd.Series(dates.values, index=np.arange(len(dates)))\n",
    "\n",
    "# compute optimal probability threshold based on f1 score\n",
    "val_idx = np.concatenate(val_idxs)\n",
    "threshold = Metrics.get_threshold(y[val_idx], y_prob_val)\n",
    "y_pred = (y_prob > threshold).astype(int)\n",
    "\n",
    "# append final threshold\n",
    "thresholds = thresholds + [threshold]\n",
    "\n",
    "# plot predictions over time\n",
    "bd = 'bd'[dataset == 'bat']\n",
    "Plots.predictions(\n",
    "    y_true=y, \n",
    "    y_probs=[y_prob_train[0], y_prob_val, y_prob_test],\n",
    "    cv_splits=[train_idxs, val_idxs, test_idx],\n",
    "    dates=dates, \n",
    "    threshold=threshold, \n",
    "    dataset=dataset,\n",
    "    save_name=f'figures/Fig1{bd}.pdf' if rolling_forecast else None,\n",
    ")\n",
    "\n",
    "# plot train/val/test splits separately\n",
    "fig = ['SI_Fig6', 'SI_Fig7'][not rolling_forecast]\n",
    "bd = 'bd'[dataset == 'bat']\n",
    "Plots.predictions_subplots(\n",
    "    y_true=y, \n",
    "    y_probs=[y_prob_train, y_prob_val, y_prob_test],\n",
    "    cv_splits=[train_idxs+[train_idx], val_idxs, test_idx],\n",
    "    dates=dates, \n",
    "    thresholds=thresholds, \n",
    "    dataset=dataset,\n",
    "    save_name=f'figures/{fig}{bd}.pdf',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be3f7e",
   "metadata": {},
   "source": [
    "# Print model performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f7aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Metrics)\n",
    "\n",
    "print('------------------------------------------------------------------')\n",
    "print(f'All validation folds and test set')\n",
    "print('------------------------------------------------------------------')\n",
    "print()\n",
    "Metrics.print_metrics(\n",
    "    y, \n",
    "    y_prob, \n",
    "    dates.values, \n",
    "    val_idx=val_idx, \n",
    "    test_idx=test_idx,\n",
    "    decimal=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b245dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Metrics)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(val_idxs)):\n",
    "    start_date = dates.values[val_idxs[i][0]]\n",
    "    end_date = dates.values[val_idxs[i][-1]]\n",
    "    print('------------------------------------------------------------------')\n",
    "    print(f'Validation period: {start_date} to {end_date}')\n",
    "    print('------------------------------------------------------------------')\n",
    "    print()\n",
    "    precision, recall, thresholds = Metrics.precision_recall(y[val_idxs[i]], y_prob[val_idxs[i]])\n",
    "    f1 = 2 * (precision * recall) / (precision + recall).clip(1e-8)\n",
    "    threshold_fold = Metrics.get_threshold(y[val_idxs[i]], y_prob[val_idxs[i]])\n",
    "    if np.isnan(threshold_fold):\n",
    "        threshold_fold = 0.5\n",
    "    y_pred_fold = (y_prob[val_idxs[i]] >= threshold_fold).astype(int)\n",
    "    plt.plot(y_prob[val_idxs[i]], 'k-o')\n",
    "    plt.plot(y[val_idxs[i]], '-o', color='tab:blue', alpha=0.5)\n",
    "    plt.plot(y_pred_fold, '-o', color='tab:orange', alpha=0.5)\n",
    "    plt.fill_between(\n",
    "        np.arange(len(val_idxs[i])), \n",
    "        0, y[val_idxs[i]], \n",
    "        color='tab:blue', alpha=0.5)\n",
    "    plt.fill_between(\n",
    "        np.arange(len(val_idxs[i])), \n",
    "        0, y_pred_fold, \n",
    "        color='tab:orange', alpha=0.5)\n",
    "    plt.axhline(threshold_fold, color='red', linestyle='--')\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlim([-1, len(val_idxs[i])])\n",
    "    plt.ylabel('Predicted probability')\n",
    "    plt.xlabel('Month')\n",
    "    plt.title(f'Validation period: {start_date} to {end_date}')\n",
    "    plt.show()\n",
    "    print()\n",
    "    Metrics.print_metrics(\n",
    "        y,\n",
    "        y_prob,\n",
    "        dates.values,\n",
    "        val_idx=val_idxs[i],\n",
    "        decimal=3,\n",
    "        threshold=0.5 if y[val_idxs[i]].sum() == 0 else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6234c878",
   "metadata": {},
   "source": [
    "# Plot precision-recall curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f75dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Metrics)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if dataset == 'env':\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(4*6.4, 2*4.8))\n",
    "if dataset == 'bat':\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(4*6.4, 1*4.8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i in range(len(val_idxs)):\n",
    "\n",
    "    start_date = dates.values[val_idxs[i][0]].split('-')[0]\n",
    "    end_date = dates.values[val_idxs[i][-1]].split('-')[0]\n",
    "    y_true_train = y[train_idxs[i]]\n",
    "    y_pred_train = y_prob_train[i]\n",
    "    y_true_val = y[val_idxs[i]]\n",
    "    y_pred_val = y_prob[val_idxs[i]]\n",
    "    balanced_class_weights = len(y_true_train) / (2 * np.bincount(y_true_train))\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        axs[i].set_ylabel('Precision', fontsize=20)\n",
    "    if i >= 5 or dataset == 'bat':\n",
    "        axs[i].set_xlabel('Threshold', fontsize=20)\n",
    "    axs[i].set_title(f'Fold {i+1} ({start_date} - {end_date})')\n",
    "    axs[i].set_xlim([-0.03, 1.03])\n",
    "    axs[i].set_ylim([-0.03, 1.03])\n",
    "\n",
    "    if y_true_val.sum() == 0:\n",
    "        continue\n",
    "\n",
    "    p, r, t = Metrics.precision_recall(y_true_val, y_pred_val)\n",
    "    f = 2 * (p * r) / (p + r).clip(1e-8)\n",
    "\n",
    "    axs[i].plot(t, p[:-1], 'k', label='Precision')\n",
    "    axs[i].plot(t, r[:-1], 'k', linestyle='--', label='Recall')\n",
    "    axs[i].plot(t, f[:-1], 'k', linestyle=':', label='F1 Score')\n",
    "    axs[i].scatter(t[np.argmax(f[:-1])], max(f), \n",
    "                   s=200, color='k', zorder=np.inf, label='Optimal')\n",
    "    axs[i].legend()\n",
    "\n",
    "\n",
    "start_date = dates.values[val_idx[0]].split('-')[0]\n",
    "end_date = dates.values[val_idx[-1]].split('-')[0]\n",
    "y_true_val = y[val_idx]\n",
    "y_pred_val = y_prob[val_idx]\n",
    "balanced_class_weights = len(y_true_val) / (2 * np.bincount(y_true_val))\n",
    "\n",
    "p, r, t = Metrics.precision_recall(y_true_val, y_pred_val)\n",
    "f = 2 * (p * r) / (p + r).clip(1e-8)\n",
    "\n",
    "axs[-1].plot(t, p[:-1], 'k', label='Precision')\n",
    "axs[-1].plot(t, r[:-1], 'k', linestyle='--', label='Recall')\n",
    "axs[-1].plot(t, f[:-1], 'k', linestyle=':', label='F1 Score')\n",
    "axs[-1].scatter(t[np.argmax(f[:-1])], max(f), \n",
    "                s=200, color='k', zorder=np.inf, label='Optimal')\n",
    "axs[-1].legend()\n",
    "\n",
    "axs[-1].set_xlabel('Threshold')\n",
    "axs[-1].set_title(f'All folds ({start_date} - {end_date})')\n",
    "axs[-1].set_xlim([-0.03, 1.03])\n",
    "axs[-1].set_ylim([-0.03, 1.03])\n",
    "\n",
    "plt.tight_layout()\n",
    "if rolling_forecast:\n",
    "    bd = 'bd'[dataset == 'bat']\n",
    "    plt.savefig(\n",
    "        f'figures/SI_Fig5{bd}.pdf', \n",
    "        format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d05b2f",
   "metadata": {},
   "source": [
    "# Plot feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec93926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# add intercept to features if it was optimal\n",
    "if model_best['add_intercept']:\n",
    "    _features = ['Intercept'] + features\n",
    "else:\n",
    "    _features = features\n",
    "\n",
    "# train model on full training set\n",
    "model = predict(np.arange(test_idx[0]), test_idx)[-1]\n",
    "\n",
    "# unpack GLM coefficients\n",
    "feats = np.array([rename[feature] for feature in _features])[::-1]\n",
    "coeffs = np.array(model.result_.params[::-1])\n",
    "\n",
    "# order from largest to smallest\n",
    "order = np.argsort(coeffs)\n",
    "feats, coeffs = feats[order], coeffs[order]\n",
    "\n",
    "# only keep significant features\n",
    "keep = np.abs(coeffs) > 0.2\n",
    "feats, coeffs = feats[keep], coeffs[keep]\n",
    "\n",
    "def plot_glm_coeffs(features, coeffs):\n",
    "\n",
    "    # book keeping\n",
    "    y_pos = np.arange(len(features))\n",
    "    coeffs_normalized = (coeffs / np.max(np.abs(coeffs)) + 1) / 2 # to [0, 1]\n",
    "    colors = matplotlib.colormaps['coolwarm'](coeffs_normalized)\n",
    "    switch = (coeffs > 0).sum() - 0.5\n",
    "\n",
    "    if dataset == 'bat':\n",
    "        switch -= 1\n",
    "\n",
    "    # initialize figure\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    height = 0.3 * len(features)\n",
    "    height = height + 1 if dataset == 'bat' else height\n",
    "    fig, ax = plt.subplots(figsize=(10, height))\n",
    "\n",
    "    # coefficients\n",
    "    ax.hlines(y=y_pos, xmin=0, xmax=coeffs, color=\"gray\", lw=1)\n",
    "    ax.scatter(coeffs, y_pos, s=200, c=colors, edgecolor=\"black\", zorder=np.inf)\n",
    "\n",
    "    # zero line\n",
    "    ax.axvline(0, color=\"gray\", lw=3, zorder=10)\n",
    "\n",
    "    # positive to negative switch line\n",
    "    ax.axhline(switch, color=\"gray\", lw=1, zorder=10, linestyle='--')\n",
    "\n",
    "    # format axes\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(features)\n",
    "    ax.grid(True, axis=\"both\", color=\"0.9\")\n",
    "    for spine in [\"top\", \"right\", \"left\", \"bottom\"]:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.tick_params(axis=\"both\", length=0)\n",
    "    ax.set_xlabel(\"Coefficient (log-odds)\")\n",
    "    if dataset == 'bat':\n",
    "        ax.set_ylim([-1, len(features)])\n",
    "        ax.set_xlim([-2.5, 2.5])\n",
    "    else:\n",
    "        ax.set_xlim([-6.5, 6.5])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "plot_glm_coeffs(feats, coeffs)\n",
    "if rolling_forecast:\n",
    "    ab = 'ab'[dataset == 'bat']\n",
    "    plt.savefig(\n",
    "        f'figures/SI_Fig8{ab}.pdf', \n",
    "        format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b0f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.result_.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flying-fox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

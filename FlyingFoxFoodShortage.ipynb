{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74fe623-2a3b-4234-b8c8-de9dc8780132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# general\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "from importlib import reload\n",
    "\n",
    "# modeling\n",
    "import lightgbm as lgb\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import shap\n",
    "\n",
    "# custom\n",
    "from scripts import HyperparameterTuning as HT\n",
    "from scripts import Plots, Metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "387b5115-94a5-4545-b64d-827b14a829d0",
   "metadata": {},
   "source": [
    "# Load and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d4950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "env_path = 'data/environmental_data.csv'\n",
    "bat_path = 'data/bat-level_data.csv'\n",
    "random_state = 1337\n",
    "dataset = 'env' # 'env', 'bat'\n",
    "target = 'shortage'\n",
    "rolling_forecast = True\n",
    "\n",
    "# load configs\n",
    "env_features = []\n",
    "with open('config/env_features.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        env_features.append(line.strip())\n",
    "bat_features = []\n",
    "with open('config/bat_features.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        bat_features.append(line.strip())\n",
    "rename = {}\n",
    "with open('config/rename.tsv', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split('\\t')\n",
    "        rename[line[0]] = line[1]\n",
    "\n",
    "# book keeping\n",
    "features = env_features if dataset == 'env' else bat_features\n",
    "\n",
    "# load both datasets, sort, and merge\n",
    "df_env = pd.read_csv(env_path).sort_values(\n",
    "    by=['cal_year', 'cal_month'], ascending=[True, True])\n",
    "df_bat = pd.read_csv(bat_path).sort_values(\n",
    "    by=['cal_year', 'cal_month'], ascending=[True, True])\n",
    "df = pd.merge(df_env, df_bat, on=['cal_year', 'cal_month'], how='outer')\n",
    "\n",
    "# convert categories to binary and drop missing\n",
    "df = df.replace('shortage', 1).replace('not_shortage', 0)\n",
    "df = df.dropna(subset=[target])\n",
    "df[target] = df[target].astype(int)\n",
    "\n",
    "# include season as additional feature\n",
    "to_season = {\n",
    "    12: 1,  1: 1,  2: 1,\n",
    "     3: 2,  4: 2,  5: 2,\n",
    "     6: 3,  7: 3,  8: 3,\n",
    "     9: 4, 10: 4, 11: 4,}\n",
    "df['cal_season'] = df['cal_month'].apply(lambda x: to_season[x]).astype(float)\n",
    "\n",
    "# drop rows with >50% missing features\n",
    "df = df.dropna(thresh=0.5*len(features), subset=features)\n",
    "df_missing = df.copy()\n",
    "\n",
    "# impute missing values\n",
    "n_missing = df[features].isna().sum().sum()\n",
    "n_total = len(df) * len(features)\n",
    "imp = IterativeImputer(max_iter=100, random_state=random_state)\n",
    "df[features] = imp.fit_transform(df[features])\n",
    "\n",
    "# start integer features from 0 and convert to categorical\n",
    "for feature in ['cal_year', 'cal_month']:\n",
    "    df[feature] = df[feature].astype(int)\n",
    "for feature in ['cal_season', 'cal_month']:\n",
    "    df[feature] = (df[feature] - df[feature].min()).astype('category')\n",
    "\n",
    "# reset df index starting from 0\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# summary\n",
    "print('Missing proportion: {:.2f}% values'.format(n_missing / n_total * 100))\n",
    "print('Data shape: {} months, {} features'.format(*df[features].shape))\n",
    "print('Food shortages: {} / {} ({:.2f}%)'.format(\n",
    "    df[target].sum(), len(df), df[target].sum() / len(df) * 100))\n",
    "\n",
    "# plot missing\n",
    "if dataset == 'bat':\n",
    "    Plots.plot_missing(\n",
    "        df_missing, \n",
    "        features, \n",
    "        rename, \n",
    "        verbose=True,\n",
    "        save_name='figures/SI_Fig3.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6890bdb",
   "metadata": {},
   "source": [
    "# Split data into train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6485faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "start_year = df['cal_year'].min() + 4\n",
    "test_year = 2018\n",
    "split_size = 2\n",
    "\n",
    "# convert dataframes to numpy arrays for modeling\n",
    "X, y = df[features].values, df[target].values\n",
    "years = df['cal_year'].values\n",
    "\n",
    "# get indices of training and validation sets\n",
    "split_years = np.arange(start_year, test_year, split_size)\n",
    "if rolling_forecast:\n",
    "    train_idx = np.argwhere(years < test_year).flatten()\n",
    "else:\n",
    "    train_idx = np.argwhere((years >= test_year - 4) & (years < test_year)).flatten()\n",
    "train_idxs, val_idxs = [], []\n",
    "for i, sy in enumerate(split_years):\n",
    "    if rolling_forecast:\n",
    "        train_idxs.append(np.argwhere(years < sy).flatten())\n",
    "    else:\n",
    "        train_idxs.append(np.argwhere((years >= sy-4) & (years < sy)).flatten())\n",
    "    val_idxs.append(np.argwhere((years >= sy) * (years < sy+split_size)).flatten())\n",
    "test_idx = np.argwhere(years >= test_year).flatten()\n",
    "\n",
    "# compute train/val score weights\n",
    "weights = [len(t_idx) for t_idx in train_idxs]\n",
    "\n",
    "# plot train/val/test splits\n",
    "ab = 'ab'[dataset == 'bat']\n",
    "Plots.cv_splits(\n",
    "    years, \n",
    "    cv_splits=[train_idxs, val_idxs, test_idx], \n",
    "    dataset=dataset,\n",
    "    save_name=f'figures/SI_Fig4{ab}.pdf' if rolling_forecast else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79762712",
   "metadata": {},
   "source": [
    "# Train GBDT using hyperparameter grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa55250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "np.random.seed(random_state)\n",
    "use_best = False\n",
    "\n",
    "# model class\n",
    "model_class = lgb.LGBMClassifier\n",
    "\n",
    "# add eval method to model class (minimum validation log loss)\n",
    "def evaluate(self, x, y):\n",
    "    return min(self.evals_result_['valid_0']['binary_logloss'])\n",
    "model_class.evaluate = evaluate\n",
    "\n",
    "# model parameters\n",
    "model_hyper = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1], # boosting learning rate   (default=0.1)\n",
    "    'num_leaves': [4, 8, 16], # max tree leaves for base learners  (default=31)\n",
    "    'max_bin': [4, 8, 16], # max bins that feature is bucketed     (default=255)\n",
    "    'min_child_samples': [1, 5, 10], # min data in leaf            (default=20)\n",
    "    'min_child_weight': [0.001, 0.01, 0.1], # min sum leaf hessian (default=1e-3)\n",
    "    'reg_alpha': [0.0, 0.01, 0.1], # l1 regularization             (default=0.0)\n",
    "    'reg_lambda': [0.0, 0.01, 0.1], # l2 regularization            (default=0.0)\n",
    "}\n",
    "model_fixed = {\n",
    "    'boosting_type': 'gbdt', # gradient boosting decision tree\n",
    "    'objective': 'binary', # shortage / no shortage binary classification\n",
    "    'n_estimators': 100, # number of iterations\n",
    "    'class_weight': 'balanced', # include class balance in loss function\n",
    "    'importance_type': 'split', # feature importance by number of splits\n",
    "    'n_jobs': 1, # -1: use all cores (wasteful on small datasets like this one)\n",
    "    'max_depth': 4, # constrain max tree depth to prevent overfitting\n",
    "    'cat_l2': 0, # L2 regularization for categorical features\n",
    "    'cat_smooth': 0, # smoothing for categorical features\n",
    "    'min_split_gain': 0.0, # min. reduction in loss from adding a split\n",
    "    'verbose': -1, # -1 = silent, 0 = warn, 1 = info\n",
    "    'random_state': random_state, # seed\n",
    "}\n",
    "\n",
    "# train parameters\n",
    "train_hyper = {}\n",
    "train_fixed = {\n",
    "    'feature_name': 'auto', # 'None', 'auto'\n",
    "    'categorical_feature': None, # None, 'auto'\n",
    "    'eval_metric': model_fixed['objective'],\n",
    "    'callbacks': [ # early stopping so lgbm records validation performance\n",
    "        lgb.early_stopping(model_fixed['n_estimators'],\n",
    "        verbose=False)], \n",
    "}\n",
    "\n",
    "# best parameters\n",
    "env_best = {\n",
    "    'learning_rate':     [0.1],\n",
    "    'num_leaves':        [16],\n",
    "    'max_bin':           [4],\n",
    "    'min_child_samples': [5],\n",
    "    'min_child_weight':  [0.01],\n",
    "    'reg_alpha':         [0.0],\n",
    "    'reg_lambda':        [0.01],\n",
    "}\n",
    "bat_best = {\n",
    "    'learning_rate':     [0.1],\n",
    "    'num_leaves':        [8],\n",
    "    'max_bin':           [16],\n",
    "    'min_child_samples': [5],\n",
    "    'min_child_weight':  [0.01],\n",
    "    'reg_alpha':         [0.0],\n",
    "    'reg_lambda':        [0.1],\n",
    "}\n",
    "if use_best and dataset == 'env': model_hyper = env_best\n",
    "if use_best and dataset == 'bat': model_hyper = bat_best\n",
    "\n",
    "# tune model hyperparameters\n",
    "model_best, train_best, model_list, score_list = HT.hyperparameter_tuning(\n",
    "    model_class=model_class,\n",
    "    model_hyper=model_hyper,\n",
    "    model_fixed=model_fixed,\n",
    "    train_hyper=train_hyper,\n",
    "    train_fixed=train_fixed,\n",
    "    x=X,\n",
    "    y=y,\n",
    "    train_indices=train_idxs,\n",
    "    val_indices=val_idxs,\n",
    "    weights=weights,\n",
    "    verbose=True,\n",
    ")\n",
    "time.sleep(0.5)\n",
    "\n",
    "# best iteration is that which minimizes the validation score\n",
    "def get_best_iter(m): \n",
    "    return np.nanargmin(m.evals_result_['valid_0']['binary_logloss'])\n",
    "\n",
    "# get best iteration\n",
    "score_means = [np.average(s, weights=weights) for s in score_list]\n",
    "best_models = model_list[np.nanargmin(score_means)]\n",
    "iterations = [get_best_iter(m) for m in best_models]\n",
    "best_iteration = int(np.average(iterations, weights=weights))\n",
    "model_fixed['n_estimators'] = best_iteration\n",
    "print('Best iteration:', best_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6441b9",
   "metadata": {},
   "source": [
    "# Plot model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Plots)\n",
    "reload(Metrics)\n",
    "\n",
    "def predict(train_idx, val_idx):\n",
    "    \n",
    "    # fit model\n",
    "    model = model_class(\n",
    "        **model_best, \n",
    "        **model_fixed,\n",
    "    ).fit(\n",
    "        X=X[train_idx],\n",
    "        y=y[train_idx],\n",
    "        eval_set=(X[val_idx], y[val_idx]),\n",
    "        **train_best,\n",
    "        **train_fixed,\n",
    "    )\n",
    "\n",
    "    # predict probabilities\n",
    "    y_pred_train = model.predict_proba(\n",
    "        X[train_idx], \n",
    "        num_iteration=best_iteration,\n",
    "    )[:, 1]\n",
    "    y_pred_val = model.predict_proba(\n",
    "        X[val_idx], \n",
    "        num_iteration=best_iteration,\n",
    "    )[:, 1]\n",
    "\n",
    "    return y_pred_train, y_pred_val, model\n",
    "\n",
    "# compute predictions for each set\n",
    "# y_prob_train = predict(train_idxs[0], val_idxs[0])[0]\n",
    "y_prob_train = [predict(t, v)[0] for t, v in zip(train_idxs, val_idxs)]\n",
    "y_prob_train.append(predict(train_idx, test_idx)[0])\n",
    "y_prob_val = np.concatenate([predict(t, v)[1] for t, v in zip(train_idxs, val_idxs)])\n",
    "y_prob_test = predict(np.arange(test_idx[0]), test_idx)[1]\n",
    "y_prob = np.concatenate([y_prob_train[0], y_prob_val, y_prob_test])\n",
    "\n",
    "# compute thresholds for each set\n",
    "thresholds = [Metrics.get_threshold(y[v], y_prob[v]) for v in val_idxs]\n",
    "\n",
    "# create dates from years and months\n",
    "dates = df['cal_year'].astype(str) + '-' + df['cal_month'].astype(int).astype(str)\n",
    "dates = pd.Series(dates.values, index=np.arange(len(dates)))\n",
    "\n",
    "# compute optimal probability threshold based on f1 score\n",
    "val_idx = np.concatenate(val_idxs)\n",
    "threshold = Metrics.get_threshold(y[val_idx], y_prob_val)\n",
    "y_pred = (y_prob > threshold).astype(int)\n",
    "\n",
    "# append final threshold\n",
    "thresholds = thresholds + [threshold]\n",
    "\n",
    "# plot predictions over time\n",
    "ac = 'ac'[dataset == 'bat']\n",
    "Plots.predictions(\n",
    "    y_true=y, \n",
    "    y_probs=[y_prob_train[0], y_prob_val, y_prob_test],\n",
    "    cv_splits=[train_idxs, val_idxs, test_idx],\n",
    "    dates=dates, \n",
    "    threshold=threshold, \n",
    "    dataset=dataset,\n",
    "    save_name=f'figures/Fig1{ac}.pdf' if rolling_forecast else None,\n",
    ")\n",
    "\n",
    "# plot train/val/test splits separately\n",
    "fig = ['SI_Fig6', 'SI_Fig7'][not rolling_forecast]\n",
    "ac = 'ac'[dataset == 'bat']\n",
    "Plots.predictions_subplots(\n",
    "    y_true=y, \n",
    "    y_probs=[y_prob_train, y_prob_val, y_prob_test],\n",
    "    cv_splits=[train_idxs+[train_idx], val_idxs, test_idx],\n",
    "    dates=dates, \n",
    "    thresholds=thresholds,  \n",
    "    dataset=dataset,\n",
    "    save_name=f'figures/{fig}{ac}.pdf',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be3f7e",
   "metadata": {},
   "source": [
    "# Print model performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f7aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Metrics)\n",
    "\n",
    "print('------------------------------------------------------------------')\n",
    "print(f'All validation folds and test set')\n",
    "print('------------------------------------------------------------------')\n",
    "print()\n",
    "Metrics.print_metrics(\n",
    "    y, \n",
    "    y_prob, \n",
    "    dates.values, \n",
    "    val_idx=val_idx, \n",
    "    test_idx=test_idx,\n",
    "    decimal=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d98519",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Metrics)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(val_idxs)):\n",
    "    start_date = dates.values[val_idxs[i][0]]\n",
    "    end_date = dates.values[val_idxs[i][-1]]\n",
    "    print('------------------------------------------------------------------')\n",
    "    print(f'Validation period: {start_date} to {end_date}')\n",
    "    print('------------------------------------------------------------------')\n",
    "    print()\n",
    "    precision, recall, thresholds = Metrics.precision_recall(y[val_idxs[i]], y_prob[val_idxs[i]])\n",
    "    f1 = 2 * (precision * recall) / (precision + recall).clip(1e-8)\n",
    "    threshold_fold = Metrics.get_threshold(y[val_idxs[i]], y_prob[val_idxs[i]])\n",
    "    if np.isnan(threshold_fold):\n",
    "        threshold_fold = 0.5\n",
    "    y_pred_fold = (y_prob[val_idxs[i]] >= threshold_fold).astype(int)\n",
    "    plt.plot(y_prob[val_idxs[i]], 'k-o')\n",
    "    plt.plot(y[val_idxs[i]], '-o', color='tab:blue', alpha=0.5)\n",
    "    plt.plot(y_pred_fold, '-o', color='tab:orange', alpha=0.5)\n",
    "    plt.fill_between(\n",
    "        np.arange(len(val_idxs[i])), \n",
    "        0, y[val_idxs[i]], \n",
    "        color='tab:blue', alpha=0.5)\n",
    "    plt.fill_between(\n",
    "        np.arange(len(val_idxs[i])), \n",
    "        0, y_pred_fold, \n",
    "        color='tab:orange', alpha=0.5)\n",
    "    plt.axhline(threshold_fold, color='red', linestyle='--')\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlim([-1, len(val_idxs[i])])\n",
    "    plt.ylabel('Predicted probability')\n",
    "    plt.xlabel('Month')\n",
    "    plt.title(f'Validation period: {start_date} to {end_date}')\n",
    "    plt.show()\n",
    "    print()\n",
    "    Metrics.print_metrics(\n",
    "        y,\n",
    "        y_prob,\n",
    "        dates.values,\n",
    "        val_idx=val_idxs[i],\n",
    "        decimal=3,\n",
    "        threshold=0.5 if y[val_idxs[i]].sum() == 0 else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58190b71",
   "metadata": {},
   "source": [
    "# Plot precision-recall curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d9cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Metrics)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if dataset == 'env':\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(4*6.4, 2*4.8))\n",
    "if dataset == 'bat':\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(4*6.4, 1*4.8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i in range(len(val_idxs)):\n",
    "\n",
    "    start_date = dates.values[val_idxs[i][0]].split('-')[0]\n",
    "    end_date = dates.values[val_idxs[i][-1]].split('-')[0]\n",
    "    y_true_train = y[train_idxs[i]]\n",
    "    y_pred_train = y_prob_train[i]\n",
    "    y_true_val = y[val_idxs[i]]\n",
    "    y_pred_val = y_prob[val_idxs[i]]\n",
    "    balanced_class_weights = len(y_true_train) / (2 * np.bincount(y_true_train))\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        axs[i].set_ylabel('Precision', fontsize=20)\n",
    "    if i >= 5 or dataset == 'bat':\n",
    "        axs[i].set_xlabel('Threshold', fontsize=20)\n",
    "    axs[i].set_title(f'Fold {i+1} ({start_date} - {end_date})')\n",
    "    axs[i].set_xlim([-0.03, 1.03])\n",
    "    axs[i].set_ylim([-0.03, 1.03])\n",
    "\n",
    "    if y_true_val.sum() == 0:\n",
    "        continue\n",
    "\n",
    "    p, r, t = Metrics.precision_recall(y_true_val, y_pred_val)\n",
    "    f = 2 * (p * r) / (p + r).clip(1e-8)\n",
    "\n",
    "    axs[i].plot(t, p[:-1], 'k', label='Precision')\n",
    "    axs[i].plot(t, r[:-1], 'k', linestyle='--', label='Recall')\n",
    "    axs[i].plot(t, f[:-1], 'k', linestyle=':', label='F1 Score')\n",
    "    axs[i].scatter(t[np.argmax(f[:-1])], max(f), \n",
    "                   s=200, color='k', zorder=np.inf, label='Optimal')\n",
    "    axs[i].legend()\n",
    "\n",
    "\n",
    "start_date = dates.values[val_idx[0]].split('-')[0]\n",
    "end_date = dates.values[val_idx[-1]].split('-')[0]\n",
    "y_true_val = y[val_idx]\n",
    "y_pred_val = y_prob[val_idx]\n",
    "balanced_class_weights = len(y_true_val) / (2 * np.bincount(y_true_val))\n",
    "\n",
    "p, r, t = Metrics.precision_recall(y_true_val, y_pred_val)\n",
    "f = 2 * (p * r) / (p + r).clip(1e-8)\n",
    "\n",
    "axs[-1].plot(t, p[:-1], 'k', label='Precision')\n",
    "axs[-1].plot(t, r[:-1], 'k', linestyle='--', label='Recall')\n",
    "axs[-1].plot(t, f[:-1], 'k', linestyle=':', label='F1 Score')\n",
    "axs[-1].scatter(t[np.argmax(f[:-1])], max(f), \n",
    "                s=200, color='k', zorder=np.inf, label='Optimal')\n",
    "axs[-1].legend()\n",
    "\n",
    "axs[-1].set_xlabel('Threshold')\n",
    "axs[-1].set_title(f'All folds ({start_date} - {end_date})')\n",
    "axs[-1].set_xlim([-0.03, 1.03])\n",
    "axs[-1].set_ylim([-0.03, 1.03])\n",
    "\n",
    "plt.tight_layout()\n",
    "if rolling_forecast:\n",
    "    ac = 'ac'[dataset == 'bat']\n",
    "    plt.savefig(\n",
    "        f'figures/SI_Fig5{ac}.pdf', \n",
    "        format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf23abed",
   "metadata": {},
   "source": [
    "# Compute shap values and shap interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f02d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# book keeping\n",
    "train_idx = np.argwhere(years < test_year).flatten()\n",
    "test_idx = np.argwhere(years >= test_year).flatten()\n",
    "\n",
    "# split datasets\n",
    "x_train = pd.DataFrame(X[train_idx], columns=[rename[f] for f in features])\n",
    "y_train = y[train_idx]\n",
    "x_test = pd.DataFrame(X[test_idx], columns=[rename[f] for f in features])\n",
    "y_test = y[test_idx]\n",
    "x_total = pd.DataFrame(X, columns=[rename[f] for f in features])\n",
    "y_total = y\n",
    "\n",
    "# prefit GBM Classifier on training set\n",
    "gbdt = predict(train_idx, test_idx)[2]\n",
    "\n",
    "# compute shap values [N, F]\n",
    "explainer = shap.Explainer(gbdt, algorithm='tree', seed=random_state)\n",
    "train_shap_values = explainer(x_train)#[:, :, 1] # 1 = shortage\n",
    "test_shap_values = explainer(x_test)#[:, :, 1] # 1 = shortage\n",
    "\n",
    "# compute SHAP interactions [N, F, F]\n",
    "train_shap_interactions = explainer.shap_interaction_values(x_train)\n",
    "test_shap_interactions = explainer.shap_interaction_values(x_test)\n",
    "\n",
    "# normalize shap values [F]\n",
    "train_shap_norms = np.abs(train_shap_values.values).mean(0)\n",
    "train_shap_norms = train_shap_norms / train_shap_norms.sum()\n",
    "test_shap_norms = np.abs(test_shap_values.values).mean(0)\n",
    "test_shap_norms = test_shap_norms / test_shap_norms.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e95911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "tr_per_fold_shap_values = []\n",
    "vl_per_fold_shap_values = []\n",
    "\n",
    "# compute shap values for every fold\n",
    "for tr_idx, vl_idx, model in zip(train_idxs, val_idxs, best_models):\n",
    "\n",
    "    # compute shap values\n",
    "    explainer = shap.Explainer(model, algorithm='tree', seed=random_state)\n",
    "    tr_shap = explainer(pd.DataFrame(X[tr_idx], columns=[rename[f] for f in features]))\n",
    "    vl_shap = explainer(pd.DataFrame(X[vl_idx], columns=[rename[f] for f in features]))\n",
    "\n",
    "    # extract values (T, F)\n",
    "    tr_shap_values = np.abs(tr_shap.values).mean(0)\n",
    "    vl_shap_values = np.abs(vl_shap.values).mean(0)\n",
    "\n",
    "    tr_per_fold_shap_values.append(tr_shap_values)\n",
    "    vl_per_fold_shap_values.append(vl_shap_values)\n",
    "\n",
    "# append final test set\n",
    "tr_per_fold_shap_values.append(np.abs(train_shap_values.values).mean(0))\n",
    "vl_per_fold_shap_values.append(np.abs(test_shap_values.values).mean(0))\n",
    "\n",
    "# convert to numpy arrays\n",
    "tr_per_fold_shap_values = np.array(tr_per_fold_shap_values)\n",
    "vl_per_fold_shap_values = np.array(vl_per_fold_shap_values)\n",
    "\n",
    "n_folds = len(train_idxs)\n",
    "height = 0.3 * len(features)\n",
    "height = height + 1 if dataset == 'bat' else height\n",
    "x_ticks = list(np.arange(1, n_folds+1)) + ['Test']\n",
    "y_ticks = [rename[f] for f in features]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(1.5*n_folds, height))\n",
    "im0 = ax.imshow(\n",
    "    tr_per_fold_shap_values.T,\n",
    "    aspect='auto',\n",
    "    cmap='Blues',\n",
    "    interpolation='nearest',\n",
    "    vmin=0, vmax=2)\n",
    "fig.colorbar(im0, ax=ax, label='\\nMean(|SHAP value|)')\n",
    "ax.set_yticks(np.arange(len(features)), y_ticks)\n",
    "ax.set_xticks(np.arange(n_folds+1), x_ticks)\n",
    "ax.set_xlabel('Fold')\n",
    "ax.grid(False)\n",
    "if rolling_forecast:\n",
    "    ac = 'ac'[dataset == 'bat']\n",
    "    plt.savefig(\n",
    "        f'figures/SI_Fig9{ac}.pdf',\n",
    "        format='pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(1.5*n_folds, height))\n",
    "im0 = ax.imshow(\n",
    "    vl_per_fold_shap_values.T,\n",
    "    aspect='auto',\n",
    "    cmap='Blues',\n",
    "    interpolation='nearest',\n",
    "    vmin=0, vmax=2)\n",
    "fig.colorbar(im0, ax=ax, label='\\nMean(|SHAP value|)')\n",
    "ax.set_yticks(np.arange(len(features)), y_ticks)\n",
    "ax.set_xticks(np.arange(n_folds+1), x_ticks)\n",
    "ax.set_xlabel('Fold')\n",
    "ax.grid(False)\n",
    "if rolling_forecast:\n",
    "    bd = 'bd'[dataset == 'bat']\n",
    "    plt.savefig(\n",
    "        f'figures/SI_Fig9{bd}.pdf',\n",
    "        format='pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f94136",
   "metadata": {},
   "source": [
    "# Plot shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349d6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# options\n",
    "max_display = (train_shap_norms > 0.025).sum()\n",
    "order = list(np.argsort(train_shap_norms)[::-1])\n",
    "cmap = 'coolwarm'\n",
    "ab = 'ab'[dataset == 'bat']\n",
    "\n",
    "# plot shap values for training set\n",
    "Plots.shap_beeswarm(\n",
    "    shap_values=train_shap_values, \n",
    "    max_display=max_display,\n",
    "    split='train',\n",
    "    order=order, \n",
    "    save_name=f'figures/Fig2{ab}1.pdf',\n",
    ")\n",
    "\n",
    "# plot shap values for test set\n",
    "Plots.shap_beeswarm(\n",
    "    shap_values=test_shap_values, \n",
    "    max_display=max_display,\n",
    "    split='test',\n",
    "    order=order, \n",
    "    save_name=f'figures/Fig2{ab}2.pdf',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f7efb2",
   "metadata": {},
   "source": [
    "# Plot shap interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c7897",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.loc[test_idx]\n",
    "idx = np.where((df_test['cal_year'] == 2023).values)[0]\n",
    "import matplotlib.pyplot as plt\n",
    "for i, sample_ind in enumerate(idx):\n",
    "    shap.plots.waterfall(test_shap_values[sample_ind], max_display=max_display, show=False)\n",
    "    plt.title(f'{i+1}/2023 SHAP waterfall plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d86353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top two feature names, values, shaps, and interactions\n",
    "f1 = features[order[0]]\n",
    "f2 = features[order[1]]\n",
    "d1 = x_train[rename[f1]].values.copy()\n",
    "d2 = x_train[rename[f2]].values.copy()\n",
    "s1 = train_shap_values.values[:, features.index(f1)].copy()\n",
    "s2 = train_shap_values.values[:, features.index(f2)].copy()\n",
    "i = 2*train_shap_interactions[:, features.index(f1), features.index(f2)]\n",
    "\n",
    "# prepare data\n",
    "x_dt = np.concatenate([d1[:, None], d2[:, None]], axis=1)\n",
    "y1 = (np.sign(s1) > 0).astype(int)\n",
    "y2 = (np.sign(s2) > 0).astype(int)\n",
    "yi = (np.sign(i) > 0).astype(int)\n",
    "\n",
    "# individual splits\n",
    "individual_splits = [\n",
    "    Metrics.optimal_shap_splits(x_dt[:, 0:1], y1, [f1])[1][0],\n",
    "    Metrics.optimal_shap_splits(x_dt[:, 1:2], y2, [f2])[1][0]]\n",
    "\n",
    "# interaction splits\n",
    "interaction_splits = Metrics.optimal_shap_splits(x_dt, yi, [f1, f2])[1]\n",
    "\n",
    "# plot shap interactions\n",
    "ab = 'ab'[dataset == 'bat']\n",
    "Plots.shap_interactions(\n",
    "    feature_names=[f1, f2],\n",
    "    feature_data=[d1, d2],\n",
    "    feature_shaps=[s1, s2],\n",
    "    feature_interactions=i,\n",
    "    individual_splits=individual_splits,\n",
    "    interaction_splits=interaction_splits,\n",
    "    rename=rename,\n",
    "    save_name=f'figures/SI_Fig10{ab}.pdf',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c408439f",
   "metadata": {},
   "source": [
    "# Plot threshold model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d58d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# plot threshold model\n",
    "#\n",
    "\n",
    "# book keeping\n",
    "if dataset == 'env':\n",
    "    rules = [\n",
    "        lambda x, t: (x >= t).astype(int), \n",
    "        lambda x, t: (x >= t).astype(int)]\n",
    "if dataset == 'bat':\n",
    "    rules = [\n",
    "        lambda x, t: (x <= t).astype(int), \n",
    "        lambda x, t: (x > t).astype(int)]\n",
    "d1 = x_total[rename[f1]].values.copy()\n",
    "d2 = x_total[rename[f2]].values.copy()\n",
    "\n",
    "# plot threshold model\n",
    "ab = 'ab'[dataset == 'bat']\n",
    "Plots.threshold_model(\n",
    "    y_true=y,\n",
    "    dates=dates,\n",
    "    feature_names=[rename[f1], rename[f2]],\n",
    "    feature_data=[d1, d2],\n",
    "    feature_splits=interaction_splits,\n",
    "    feature_rules=rules,\n",
    "    train_idx=train_idx,\n",
    "    test_idx=test_idx,\n",
    "    dataset=dataset,\n",
    "    save_name=f'figures/Fig3{ab}.pdf',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1529c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print individual-level metrics\n",
    "split1, split2 = individual_splits\n",
    "y_ind_test = rules[0](d1[test_idx], split1) * rules[1](d2[test_idx], split2)\n",
    "Metrics.print_metrics(\n",
    "    y, \n",
    "    np.concatenate([np.zeros(len(train_idx)), y_ind_test]),\n",
    "    dates.values, \n",
    "    threshold=0.5,\n",
    "    test_idx=test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4c7011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print interaction-level metrics\n",
    "split1, split2 = interaction_splits\n",
    "y_int_test = rules[0](d1[test_idx], split1) * rules[1](d2[test_idx], split2)\n",
    "Metrics.print_metrics(\n",
    "    y, \n",
    "    np.concatenate([np.zeros(len(train_idx)), y_int_test]),\n",
    "    dates.values, \n",
    "    threshold=0.5,\n",
    "    test_idx=test_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flying-fox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
